{
    "version": 1,
    "zapps": [
        {
            "category": "Data science",
            "name": "Distributed PySpark notebook",
            "description": "spark.json",
            "readable_descr": "README.md",
            "parameters": [
                {
                    "kind": "environment",
                    "name": "SPARK_DRIVER_RAM",
                    "readable_name": "Spark driver memory (bytes)",
                    "description": "Driver memory, must be less than the memory limit for the jupyter service",
                    "type": "int",
                    "default": 2147483648,
                    "min": 536870912,
                    "max": 68719476736,
                    "step": 536870912
                },
                {
                    "kind": "environment",
                    "name": "SPARK_WORKER_RAM",
                    "readable_name": "Spark worker memory (bytes)",
                    "description": "Worker memory, must be less than the memory limit for the worker service",
                    "type": "int",
                    "default": 11274289152,
                    "min": 536870912,
                    "max": 68719476736,
                    "step": 536870912
                },
                {
                    "kind": "environment",
                    "name": "SPARK_WORKER_CORES",
                    "readable_name": "Spark worker cores",
                    "description": "Number of cores each worker has access to, must be equal to the core limit for the worker service",
                    "type": "int",
                    "default": 6,
                    "min": 1,
                    "max": 16,
                    "step": 1
                }
            ]
        }
    ]
}
